import 'dart:async';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:logger/logger.dart';
import '../models/config.dart';
import '../services/websocket_service.dart';
import '../services/activation_service.dart';
import '../services/audio_service.dart';
import '../services/vad_service.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:uuid/uuid.dart';
import 'dart:math';
import 'dart:convert';
import '../services/tts_playback_service.dart';

/// Bot states
enum BotState { idle, listening, thinking, speaking, error }

/// Bot emotions
enum BotEmotion { neutral, happy, thinking, listening, speaking, sad, error }

/// Main Bot Provider - FIXED VERSION
class BotProvider extends ChangeNotifier {
  final Logger _logger = Logger();

  // Services
  XiaozhiConfig? _config;
  XiaozhiWebSocketService? _wsService;
  ActivationService? _activationService;
  final AudioService _audioService = AudioService();
  final VadService _vadService = VadService();
  final TtsPlaybackService _ttsPlayback = TtsPlaybackService();

  // State
  BotState _state = BotState.idle;
  BotState _stateBeforeDisconnect =
      BotState.idle; // ‚úÖ FIX 4: L∆∞u state tr∆∞·ªõc disconnect
  BotEmotion _emotion = BotEmotion.neutral;
  bool _isActivated = false;
  bool _isConnected = false;
  String? _activationCode;

  // ‚úÖ FIX 1: Th√™m field ƒë·ªÉ l∆∞u listening mode
  ListeningMode _currentListeningMode = ListeningMode.autoStop;

  // ‚úÖ FIX 3: Th√™m lock ƒë·ªÉ tr√°nh race condition
  bool _isTransitioning = false;

  // ‚úÖ FIX 1: Th√™m timer cho VAD timeout
  Timer? _vadSpeechEndTimer;

  // Text
  String _currentTtsText = '';
  String _currentAsrText = '';
  final List<ChatMessage> _messages = [];
  final uuid = Uuid();

  // Subscriptions
  StreamSubscription? _ttsSubscription;
  StreamSubscription? _asrSubscription;
  StreamSubscription? _audioDataSubscription;
  StreamSubscription? _pcmDataSubscription; // For VAD
  StreamSubscription? _vadSubscription;
  StreamSubscription? _connectionStateSubscription;
  StreamSubscription? _ttsPlaybackSubscription;
  StreamSubscription? _recordingStateSubscription; // ‚úÖ FIX 5: Th√™m subscription
  // Auto voice detection mode
  bool _autoVoiceMode = false;
  bool _isMonitoringVoice = false;
  StreamSubscription? _autoVoiceSubscription;
  Timer? _autoRestartTimer;
  Timer? _autoListeningCheckTimer;
  Timer? _speakingTimeoutTimer; // ‚úÖ NEW: Timer ƒë·ªÉ check speaking timeout
  // Getters
  BotState get state => _state;
  BotEmotion get emotion => _emotion;
  bool get isActivated => _isActivated;
  bool get isConnected => _isConnected;
  String? get activationCode => _activationCode;
  String get currentTtsText => _currentTtsText;
  String get currentAsrText => _currentAsrText;
  List<ChatMessage> get messages => List.unmodifiable(_messages);
  bool get isListening => _state == BotState.listening;
  bool get isSpeaking => _state == BotState.speaking;
  bool get autoVoiceMode => _autoVoiceMode;
  bool get isMonitoringVoice => _isMonitoringVoice;

  // Bot mode
  String _botMode = 'mybot'; // 'demo' or 'mybot'
  String get botMode => _botMode;
  bool get isDemoMode => _botMode == 'demo';

  // ============================================================================
  // Initialization
  // ============================================================================

  /// Initialize with mode: 'demo' or 'mybot'
  Future<void> initialize({
    String? deviceId,
    String? clientId,
    String mode = 'mybot',
  }) async {
    try {
      _logger.i('ü§ñ Initializing bot (mode: $mode)...');
      _botMode = mode;

      final prefs = await SharedPreferences.getInstance();

      // Check if user has activated their own bot
      final hasActivatedOwnBot =
          prefs.getBool('has_activated_own_bot') ?? false;

      // If user has activated own bot, force mybot mode
      if (hasActivatedOwnBot && mode == 'demo') {
        _logger.i('‚ö†Ô∏è User has activated own bot, switching to mybot mode');
        _botMode = 'mybot';
        mode = 'mybot';
      }

      String finalDeviceId;
      String finalClientId;
      String finalSerialNumber;
      String finalHmacKey;

      if (mode == 'demo') {
        // ‚úÖ DEMO MODE - Use fixed credentials
        _logger.i('üéÆ Using DEMO bot credentials');
        finalDeviceId = '1a:a6:1d:33:d8:5c';
        finalClientId = '6497ff47-d223-4c32-93af-068469f818c8';
        finalSerialNumber = 'DEMO-BOT-001';
        finalHmacKey = _generateHmacKey(); // Generate temp key

        // Don't save demo credentials
      } else {
        // ‚úÖ MY BOT MODE - Use saved or generated credentials
        _logger.i('üë§ Using MY bot credentials');
        final savedDeviceId = prefs.getString('device_id');
        final savedClientId = prefs.getString('client_id');
        final serialNumber = prefs.getString('serial_number');
        final hmacKey = prefs.getString('hmac_key');

        finalDeviceId = deviceId ?? savedDeviceId ?? _generateDeviceId();
        finalClientId = clientId ?? savedClientId ?? _generateClientId();
        finalSerialNumber = serialNumber ?? generateSerialFromUuid();
        finalHmacKey = hmacKey ?? _generateHmacKey();

        // Save my bot credentials
        if (savedDeviceId == null) {
          await prefs.setString('device_id', finalDeviceId);
        }
        if (savedClientId == null) {
          await prefs.setString('client_id', finalClientId);
        }
        if (serialNumber == null) {
          await prefs.setString('serial_number', finalSerialNumber);
        }
        if (hmacKey == null) {
          await prefs.setString('hmac_key', finalHmacKey);
        }
      }

      _config = XiaozhiConfig(
        deviceId: finalDeviceId,
        clientId: finalClientId,
        serialNumber: finalSerialNumber,
        hmacKey: finalHmacKey,
      );

      _activationService = ActivationService(_config!);
      _wsService = XiaozhiWebSocketService(_config!);

      _setupWebSocketCallbacks();

      if (mode == 'demo') {
        // ‚úÖ DEMO MODE - Skip activation check, connect directly
        _logger.i('üéÆ Demo mode: Skipping activation, connecting directly...');
        _isActivated = true;
        await connect();
      } else {
        // ‚úÖ MY BOT MODE - Check activation status
        _logger.i('üì° Checking activation status...');
        final response = await _activationService!.checkOtaStatus();

        if (response.needsActivation) {
          _activationCode = response.verificationCode;
          _isActivated = false;
          _updateEmotion(BotEmotion.neutral);
          _logger.i('üîë Need activation: $_activationCode');
          _startActivation();
        } else {
          _isActivated = true;
          _logger.i('‚úÖ Already activated');

          // Mark that user has activated own bot
          await prefs.setBool('has_activated_own_bot', true);

          await connect();
        }
      }

      _audioService.init();
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Initialization error: $e');
      _updateState(BotState.error);
      _updateEmotion(BotEmotion.error);
    }
  }

  String generateSerialFromUuid() {
    final u = uuid.v4().replaceAll('-', '');
    final part1 = u.substring(0, 8);
    final part2 = u.substring(20, 32);
    return 'SN-${part1}-${part2}';
  }

  String _generateHmacKey() {
    final random = Random.secure();
    final bytes = List<int>.generate(32, (_) => random.nextInt(256));
    return base64Encode(bytes);
  }

  String _generateDeviceId() {
    return randomMac();
  }

  String _toHex(int v) => v.toRadixString(16).padLeft(2, '0').toUpperCase();

  String randomMac({bool locallyAdministered = true}) {
    final rnd = Random.secure();
    final bytes = List<int>.generate(6, (_) => rnd.nextInt(256));
    int first = bytes[0];
    first = first & 0xFE;
    if (locallyAdministered) {
      first = first | 0x02;
    } else {
      first = first & 0xFD;
    }
    bytes[0] = first;
    return bytes.map(_toHex).join(':').toLowerCase();
  }

  String _generateClientId() {
    return uuid.v4().toLowerCase();
  }

  // ============================================================================
  // Bot Mode Management
  // ============================================================================

  /// Check if user can switch back to demo mode
  Future<bool> canSwitchToDemo() async {
    final prefs = await SharedPreferences.getInstance();
    return !(prefs.getBool('has_activated_own_bot') ?? false);
  }

  /// Switch to My Bot mode
  Future<void> switchToMyBot() async {
    _logger.i('üîÑ Switching to My Bot mode...');

    // Disconnect current connection
    await disconnect();

    // Clear demo mode
    _botMode = 'mybot';

    // Reinitialize with mybot mode
    await initialize(mode: 'mybot');
  }

  /// Switch to Demo mode (only if user hasn't activated own bot)
  Future<void> switchToDemo() async {
    if (!await canSwitchToDemo()) {
      _logger.w('‚ö†Ô∏è Cannot switch to demo - user has activated own bot');
      return;
    }

    _logger.i('üîÑ Switching to Demo mode...');

    // Disconnect current connection
    await disconnect();

    // Set demo mode
    _botMode = 'demo';

    // Reinitialize with demo mode
    await initialize(mode: 'demo');
  }

  /// Setup WebSocket callbacks
  void _setupWebSocketCallbacks() {
    // TTS stream
    _ttsSubscription = _wsService!.ttsTextStream.listen((text) {
      _currentTtsText = text;
      _addMessage(ChatMessage(text: text, isUser: false));

      // ‚úÖ FIX 2: CH·ªà update state n·∫øu kh√¥ng ƒëang listening
      if (_state != BotState.listening) {
        _updateState(BotState.speaking);
        _updateEmotion(BotEmotion.speaking);

        // ‚úÖ FIX M·ªöI: T·∫ÆT recording NGAY khi bot b·∫Øt ƒë·∫ßu n√≥i
        // Kh√¥ng ƒë·ª£i TTS audio play ƒë·ªÉ tr√°nh echo/ng·∫Øt l·ªùi
        if (_autoVoiceMode && _audioService.isRecording) {
          _logger.i('üîá Auto mode: Stopping recording - bot starting to speak');
          _audioService.stopRecording();
        }
      }

      _logger.i('üîä TTS: $text');
      notifyListeners();
    });

    // ASR stream
    _asrSubscription = _wsService!.asrTextStream.listen((text) {
      _currentAsrText = text;
      _addMessage(ChatMessage(text: text, isUser: true));
      _logger.i('üé§ ASR: $text');
      notifyListeners();
    });

    // Connection state
    _connectionStateSubscription = _wsService!.connectionStateStream.listen((
      state,
    ) {
      _isConnected = state == ConnectionState.connected;
      _logger.i('üîå Connection state: $state');

      // ‚úÖ FIX 4: X·ª≠ l√Ω connection loss
      if (state == ConnectionState.disconnected && !_isConnected) {
        _handleConnectionLoss();
      }

      notifyListeners();
    });

    // Audio data stream
    _audioDataSubscription = _audioService.audioDataStream.listen((opusData) {
      // Ch·ªâ g·ª≠i audio ƒë·∫øn server khi ƒëang listening
      if (_state == BotState.listening) {
        _wsService?.sendAudio(opusData);
      }
    });

    // PCM data stream for VAD processing
    _pcmDataSubscription = _audioService.pcmDataStream.listen(
      (pcmData) {
        // ‚úÖ FIX: CH·ªà process VAD khi bot KH√îNG ƒëang speaking
        // Tr√°nh detect gi·ªçng n√≥i khi bot ƒëang n√≥i v√† ng·∫Øt l·ªùi bot
        if (_state != BotState.speaking) {
          _vadService.processFrame(pcmData);
        } else {
          // Bot ƒëang n√≥i, b·ªè qua VAD processing
          // _logger.d('‚è≠Ô∏è Skipping VAD - bot is speaking');
        }
      },
      onError: (error) {
        _logger.e('‚ùå PCM stream error: $error');
      },
      onDone: () {
        _logger.w('‚ö†Ô∏è PCM stream closed');
        // N·∫øu auto mode ƒëang b·∫≠t, restart recording
        if (_autoVoiceMode && _isMonitoringVoice) {
          _logger.i(
            'üîÑ PCM stream closed, restarting recording for auto mode...',
          );
          Future.delayed(Duration(milliseconds: 100), () async {
            if (_autoVoiceMode && _isMonitoringVoice) {
              await _audioService.startRecording();
            }
          });
        }
      },
    );

    // TTS Audio stream - ‚úÖ CHUNKED STREAMING VERSION
    _wsService!.onIncomingAudio((opusData) {
      _logger.d('üîä Received TTS audio: ${opusData.length} bytes');

      // ‚úÖ Add frame to streaming (s·∫Ω t·ª± ƒë·ªông t·∫°o chunk v√† play)
      _ttsPlayback.addOpusFrame(opusData);
    });

    // ‚úÖ FIX 2: TTS Playback state - v·ªõi state check v√† auto mode restart
    _ttsPlaybackSubscription = _ttsPlayback.playbackStateStream.listen((
      isPlaying,
    ) {
      if (isPlaying) {
        // CH·ªà update n·∫øu kh√¥ng ƒëang listening
        if (_state != BotState.listening) {
          _updateState(BotState.speaking);
          _updateEmotion(BotEmotion.speaking);

          // ‚úÖ FIX: T·∫ÆT recording khi bot ƒëang n√≥i ƒë·ªÉ tr√°nh echo
          if (_autoVoiceMode && _audioService.isRecording) {
            _logger.i('üîá Auto mode: Pausing recording while bot speaks');
            _audioService.stopRecording();
          }

          // ‚úÖ NEW: Set timeout ƒë·ªÉ force reset n·∫øu bot speaking qu√° l√¢u (30s)
          _speakingTimeoutTimer?.cancel();
          _speakingTimeoutTimer = Timer(Duration(seconds: 30), () {
            if (_state == BotState.speaking) {
              _logger.w('‚ö†Ô∏è Speaking timeout - force reset to idle');
              _updateState(BotState.idle);
              _updateEmotion(BotEmotion.neutral);

              if (_autoVoiceMode && _isMonitoringVoice) {
                _vadService.reset();
                Future.delayed(Duration(milliseconds: 200), () async {
                  if (_autoVoiceMode && !_audioService.isRecording) {
                    await _audioService.startRecording();
                  }
                });
              }
              notifyListeners();
            }
          });
        }
      } else {
        // Cancel timeout timer
        _speakingTimeoutTimer?.cancel();
        _speakingTimeoutTimer = null;

        // CH·ªâ v·ªÅ idle n·∫øu ƒëang speaking
        if (_state == BotState.speaking) {
          _updateState(BotState.idle);
          _updateEmotion(BotEmotion.happy);

          // ‚úÖ FIX: Khi bot n√≥i xong trong auto mode, B·∫¨T L·∫†I recording
          if (_autoVoiceMode && _isMonitoringVoice) {
            _logger.i(
              'üîÑ Auto mode: Bot finished speaking, restarting recording',
            );

            // Reset VAD ƒë·ªÉ s·∫µn s√†ng
            _vadService.reset();

            // B·∫≠t l·∫°i recording sau m·ªôt ch√∫t delay
            Future.delayed(Duration(milliseconds: 300), () async {
              if (_autoVoiceMode &&
                  _isMonitoringVoice &&
                  !_audioService.isRecording) {
                _logger.i('üé§ Auto mode: Restarting recording for next input');
                await _audioService.startRecording();
              }
            });
          }
        }
      }
      notifyListeners();
    });

    // ‚úÖ FIX 1: VAD stream - v·ªõi mode check v√† timeout
    _vadSubscription = _vadService.vadEventStream.listen((event) {
      _logger.d(
        'üîä VAD Event: $event (state: $_state, autoMode: $_autoVoiceMode)',
      );

      // ‚úÖ CRITICAL: Skip n·∫øu auto mode ƒëang b·∫≠t (auto listener s·∫Ω x·ª≠ l√Ω)
      if (_autoVoiceMode) {
        _logger.d('‚è≠Ô∏è Auto mode active, skipping manual VAD handler');
        return;
      }

      if (event == VadEvent.speechStart) {
        _logger.d('üé§ Speech started');

        // H·ªßy timer n·∫øu ƒëang ch·ªù
        _vadSpeechEndTimer?.cancel();
        _vadSpeechEndTimer = null;

        _updateEmotion(BotEmotion.listening);
      } else if (event == VadEvent.speechEnd) {
        _logger.d('üîá Speech ended');

        // CH·ªà auto-stop n·∫øu mode l√† autoStop
        if (_state == BotState.listening &&
            _currentListeningMode == ListeningMode.autoStop) {
          // H·ªßy timer c≈© n·∫øu c√≥
          _vadSpeechEndTimer?.cancel();

          // Th√™m timeout 1.5s ƒë·ªÉ tr√°nh d·ª´ng qu√° s·ªõm
          _vadSpeechEndTimer = Timer(Duration(milliseconds: 1500), () {
            if (_state == BotState.listening) {
              _logger.i('‚è±Ô∏è VAD timeout - stopping listening');
              stopListening();
            }
          });
        }
      }
    });

    // ‚úÖ FIX 5: Recording state stream - sync v·ªõi bot state
    _recordingStateSubscription = _audioService.recordingStateStream.listen((
      isRecording,
    ) {
      if (!isRecording && _state == BotState.listening) {
        _logger.w('‚ö†Ô∏è Recording stopped unexpectedly while in listening state');
        _updateState(BotState.error);
        _updateEmotion(BotEmotion.error);
        notifyListeners();
      }
    });
  }

  /// Start activation process
  void _startActivation() async {
    try {
      _logger.i('üöÄ Starting activation...');
      final success = await _activationService!.activate();

      if (success) {
        _isActivated = true;
        _activationCode = null;
        _logger.i('‚úÖ Activation successful!');
        await connect();
      } else {
        _logger.e('‚ùå Activation failed');
        _updateState(BotState.error);
        _updateEmotion(BotEmotion.error);
      }

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Activation error: $e');
    }
  }

  // ============================================================================
  // Connection
  // ============================================================================

  /// Connect to WebSocket
  Future<void> connect() async {
    try {
      _logger.i('üîå Connecting to server...');
      final success = await _wsService!.connect();

      if (success) {
        _isConnected = true;

        // ‚úÖ FIX 4: Restore state n·∫øu ƒëang listening tr∆∞·ªõc khi m·∫•t k·∫øt n·ªëi
        if (_stateBeforeDisconnect == BotState.listening) {
          _logger.i('üîÑ Restoring listening state after reconnection');
          await startListening(mode: _currentListeningMode);
        } else {
          _updateState(BotState.idle);
          _updateEmotion(BotEmotion.happy);
        }

        _logger.i('‚úÖ Connected!');
      } else {
        _logger.e('‚ùå Connection failed');
        _updateState(BotState.error);
        _updateEmotion(BotEmotion.error);
      }

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Connection error: $e');
      _updateState(BotState.error);
      _updateEmotion(BotEmotion.error);
    }
  }

  /// ‚úÖ FIX 4: Handle connection loss
  void _handleConnectionLoss() {
    _logger.w('‚ö†Ô∏è Connection lost');
    _stateBeforeDisconnect = _state;

    // D·ª´ng recording n·∫øu ƒëang listening
    if (_state == BotState.listening) {
      _audioService.stopRecording();
    }
  }

  /// Disconnect
  Future<void> disconnect() async {
    await _wsService?.disconnect();
    _isConnected = false;
    _updateState(BotState.idle);
    notifyListeners();
  }

  // ============================================================================
  // Voice interaction
  // ============================================================================

  /// ‚úÖ FIX 1 & 3: Start listening v·ªõi lock v√† mode tracking
  Future<void> startListening({
    ListeningMode mode = ListeningMode.autoStop,
  }) async {
    // ‚úÖ FIX 3: Check lock
    if (_isTransitioning) {
      _logger.w('‚ö†Ô∏è Already transitioning state');
      return;
    }

    if (!_isConnected) {
      _logger.w('‚ö†Ô∏è Not connected');
      return;
    }

    _isTransitioning = true; // Lock

    try {
      _logger.i('üé§ Starting listening (mode: $mode)...');

      // ‚úÖ FIX AUDIO: Clear old audio buffer tr∆∞·ªõc khi start listening m·ªõi
      _ttsPlayback.startNewSession();

      // ‚úÖ FIX 1: L∆∞u listening mode
      _currentListeningMode = mode;

      // Update state
      _updateState(BotState.listening);
      _updateEmotion(BotEmotion.listening);

      // Send start listening to server
      await _wsService!.sendStartListening(mode);

      // Start audio recording
      await _audioService.startRecording();

      _logger.i('‚úÖ Listening started');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error starting listening: $e');
      _updateState(BotState.error);
    } finally {
      _isTransitioning = false; // ‚úÖ FIX 3: Unlock
    }
  }

  /// ‚úÖ STREAMING VERSION: Stop listening (ƒë∆°n gi·∫£n h∆°n nhi·ªÅu!)
  Future<void> stopListening() async {
    // ‚úÖ FIX 3: Check lock
    if (_isTransitioning) {
      _logger.w('‚ö†Ô∏è Already transitioning state');
      return;
    }

    _isTransitioning = true; // Lock

    try {
      _logger.i('üõë Stopping listening...');

      // H·ªßy VAD timer n·∫øu c√≥
      _vadSpeechEndTimer?.cancel();
      _vadSpeechEndTimer = null;

      // Stop audio recording
      await _audioService.stopRecording();

      // Send stop listening to server
      await _wsService!.sendStopListening();

      // Update state
      _updateState(BotState.thinking);
      _updateEmotion(BotEmotion.thinking);

      _logger.i('‚úÖ Listening stopped');

      // ‚úÖ STREAMING: Kh√¥ng c·∫ßn waitForAudio() n·ªØa!
      // Audio s·∫Ω t·ª± ƒë·ªông stream v√† play t·ª´ng chunk khi frames ƒë·∫øn
      // Ch·ªâ c·∫ßn ƒë·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫≠n frames ƒë·∫ßu ti√™n
      await Future.delayed(Duration(milliseconds: 200));

      // Check stream status
      final streamInfo = _ttsPlayback.getStreamInfo();
      _logger.i('üìä Stream info: $streamInfo');

      // ƒê·ª£i th√™m ƒë·ªÉ nh·∫≠n t·∫•t c·∫£ frames
      await Future.delayed(Duration(milliseconds: 500));

      // Flush remaining frames (ph·∫ßn cu·ªëi c√πng)
      await _ttsPlayback.flushRemainingFrames();

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error stopping listening: $e');
    } finally {
      _isTransitioning = false; // ‚úÖ FIX 3: Unlock
    }
  }

  /// Toggle listening
  Future<void> toggleListening() async {
    if (_state == BotState.listening) {
      await stopListening();
    } else {
      await startListening();
    }
  }

  /// Send text message
  Future<void> sendTextMessage(String text) async {
    if (!_isConnected) {
      _logger.w('‚ö†Ô∏è Not connected');
      return;
    }

    try {
      _logger.i('üì§ Sending text: $text');

      _addMessage(ChatMessage(text: text, isUser: true));
      await _wsService!.sendTextMessage(text);

      _updateState(BotState.thinking);
      _updateEmotion(BotEmotion.thinking);

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error sending text: $e');
    }
  }

  // ============================================================================
  // State management
  // ============================================================================

  void _updateState(BotState newState) {
    if (_state != newState) {
      _state = newState;
      _logger.d('üîÑ State: $_state');
      notifyListeners();
    }
  }

  void _updateEmotion(BotEmotion newEmotion) {
    if (_emotion != newEmotion) {
      _emotion = newEmotion;
      _logger.d('üòä Emotion: $_emotion');
      notifyListeners();
    }
  }

  void _addMessage(ChatMessage message) {
    _messages.add(message);
    if (_messages.length > 100) {
      _messages.removeAt(0);
    }
  }

  /// Clear messages
  void clearMessages() {
    _messages.clear();
    notifyListeners();
  }

  // ============================================================================
  // Auto Voice Mode
  // ============================================================================

  /// Enable auto voice mode - t·ª± ƒë·ªông ph√°t hi·ªán v√† b·∫Øt ƒë·∫ßu l·∫Øng nghe
  Future<void> enableAutoVoiceMode() async {
    if (!_isConnected) {
      _logger.w('‚ö†Ô∏è Not connected - cannot enable auto voice mode');
      return;
    }

    if (_autoVoiceMode) {
      _logger.w('‚ö†Ô∏è Auto voice mode already enabled');
      return;
    }

    _logger.i('ü§ñ Enabling auto voice mode...');
    _autoVoiceMode = true;

    // B·∫Øt ƒë·∫ßu monitoring voice activity
    await _startVoiceMonitoring();

    notifyListeners();
  }

  /// Disable auto voice mode
  Future<void> disableAutoVoiceMode() async {
    if (!_autoVoiceMode) {
      _logger.w('‚ö†Ô∏è Auto voice mode already disabled');
      return;
    }

    _logger.i('üõë Disabling auto voice mode...');
    _autoVoiceMode = false;

    // D·ª´ng monitoring
    await _stopVoiceMonitoring();

    // N·∫øu ƒëang listening th√¨ stop
    if (_state == BotState.listening) {
      await stopListening();
    }

    // ‚úÖ FIX: Reset v·ªÅ idle state khi t·∫Øt auto mode
    if (_state != BotState.speaking) {
      _updateState(BotState.idle);
      _updateEmotion(BotEmotion.neutral);
    }

    notifyListeners();
  }

  /// Toggle auto voice mode
  Future<void> toggleAutoVoiceMode() async {
    if (_autoVoiceMode) {
      await disableAutoVoiceMode();
    } else {
      await enableAutoVoiceMode();
    }
  }

  /// B·∫Øt ƒë·∫ßu monitoring voice activity
  Future<void> _startVoiceMonitoring() async {
    if (_isMonitoringVoice) {
      _logger.w('‚ö†Ô∏è Already monitoring voice');
      return;
    }

    try {
      _logger.i('üëÇ Starting voice monitoring...');
      _isMonitoringVoice = true;

      // ‚úÖ FIX: ƒê·∫£m b·∫£o bot ·ªü idle state khi b·∫Øt ƒë·∫ßu monitoring
      if (_state != BotState.listening && _state != BotState.speaking) {
        _logger.i('üîÑ Setting bot to idle state for auto mode');
        _updateState(BotState.idle);
        _updateEmotion(BotEmotion.happy);
      }

      // Reset VAD service
      _vadService.reset();

      // B·∫Øt ƒë·∫ßu recording ƒë·ªÉ monitor
      final recordingStarted = await _audioService.startRecording();
      if (!recordingStarted) {
        _logger.e('‚ùå Failed to start recording for monitoring');
        _isMonitoringVoice = false;
        return;
      }
      _logger.i('‚úÖ Recording started for monitoring');

      // Subscribe to VAD events cho auto mode
      _autoVoiceSubscription = _vadService.vadEventStream.listen(
        (event) {
          if (!_autoVoiceMode) {
            _logger.d('‚ö†Ô∏è VAD event but auto mode disabled, ignoring');
            return;
          }

          _logger.i('üîä Auto VAD Event: $event (state: $_state)');

          if (event == VadEvent.speechStart) {
            _logger.i('üé§ Auto: Speech detected');

            // T·ª± ƒë·ªông b·∫Øt ƒë·∫ßu listening khi ph√°t hi·ªán gi·ªçng n√≥i
            // CH·ªà n·∫øu bot ƒëang idle (kh√¥ng listening, kh√¥ng speaking)
            if (_state == BotState.idle) {
              _logger.i('‚úÖ Auto: Starting listening from idle state');
              _autoStartListening();
            } else if (_state == BotState.speaking) {
              _logger.d('‚è≠Ô∏è Auto: Bot is speaking, will wait for finish');
              // Kh√¥ng l√†m g√¨, ƒë·ª£i bot n√≥i xong s·∫Ω t·ª± restart recording
            } else {
              _logger.d('‚ö†Ô∏è Auto: Not in idle state, current: $_state');
            }
          } else if (event == VadEvent.speechEnd) {
            _logger.d('üîá Auto: Speech ended');

            // Trong auto mode, khi speech end th√¨ auto stop
            if (_state == BotState.listening) {
              _logger.i('‚úÖ Auto: Stopping listening');
              _autoStopListening();
            } else if (_state == BotState.thinking) {
              // ‚úÖ FIX: N·∫øu ƒëang thinking m√† c√≥ speechEnd (im l·∫∑ng ban ƒë·∫ßu)
              // th√¨ reset v·ªÅ idle ƒë·ªÉ s·∫µn s√†ng
              _logger.i('üîÑ Auto: In thinking state, resetting to idle');
              _updateState(BotState.idle);
              _updateEmotion(BotEmotion.happy);
              notifyListeners();
            } else if (_state == BotState.speaking) {
              // ‚úÖ FIX M·ªöI: N·∫øu bot ƒëang speaking m√† detect speechEnd
              // c√≥ th·ªÉ l√† bot ƒë√£ n√≥i xong nh∆∞ng TTS ch∆∞a emit completed
              // ƒê·ª£i m·ªôt ch√∫t r·ªìi check l·∫°i
              _logger.i(
                '‚è±Ô∏è Auto: Bot speaking, user silent - checking if bot finished',
              );

              Future.delayed(Duration(milliseconds: 500), () {
                // N·∫øu v·∫´n ƒëang speaking sau 500ms v√† kh√¥ng c√≥ audio
                // th√¨ force v·ªÅ idle
                if (_state == BotState.speaking && !_ttsPlayback.isPlaying) {
                  _logger.i(
                    'üîÑ Auto: Force reset to idle - bot seems finished',
                  );
                  _updateState(BotState.idle);
                  _updateEmotion(BotEmotion.happy);

                  // Restart recording cho auto mode
                  if (_autoVoiceMode && _isMonitoringVoice) {
                    _vadService.reset();
                    Future.delayed(Duration(milliseconds: 200), () async {
                      if (_autoVoiceMode && !_audioService.isRecording) {
                        await _audioService.startRecording();
                      }
                    });
                  }
                  notifyListeners();
                }
              });
            } else {
              _logger.d('‚ö†Ô∏è Auto: Not in listening state, current: $_state');
            }
          }
        },
        onError: (error) {
          _logger.e('‚ùå Auto VAD subscription error: $error');
        },
        onDone: () {
          _logger.w('‚ö†Ô∏è Auto VAD subscription closed');
        },
      );

      _logger.i('‚úÖ Voice monitoring started');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error starting voice monitoring: $e');
      _isMonitoringVoice = false;
    }
  }

  /// D·ª´ng monitoring voice activity
  Future<void> _stopVoiceMonitoring() async {
    if (!_isMonitoringVoice) {
      return;
    }

    try {
      _logger.i('üõë Stopping voice monitoring...');

      // Cancel subscription
      _autoVoiceSubscription?.cancel();
      _autoVoiceSubscription = null;

      // Cancel timers
      _autoRestartTimer?.cancel();
      _autoRestartTimer = null;
      _autoListeningCheckTimer?.cancel();
      _autoListeningCheckTimer = null;

      // ‚úÖ FIX: LU√îN stop recording khi t·∫Øt monitoring
      await _audioService.stopRecording();

      _isMonitoringVoice = false;
      _logger.i('‚úÖ Voice monitoring stopped');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error stopping voice monitoring: $e');
    }
  }

  /// Auto start listening khi ph√°t hi·ªán gi·ªçng n√≥i
  Future<void> _autoStartListening() async {
    try {
      _logger.i('ü§ñ Auto starting listening...');

      // ‚úÖ FIX: CH·ªà clear audio buffer n·∫øu bot KH√îNG ƒëang speaking
      // N·∫øu ƒëang speaking th√¨ KH√îNG clear ƒë·ªÉ tr√°nh ng·∫Øt l·ªùi bot
      if (_state != BotState.speaking && !_ttsPlayback.isPlaying) {
        _logger.d('üîÑ Clearing old audio buffer');
        _ttsPlayback.startNewSession();
      } else {
        _logger.d('‚è≠Ô∏è Bot is speaking, keeping audio buffer');
      }

      // Update state
      _updateState(BotState.listening);
      _updateEmotion(BotEmotion.listening);

      // Send start listening to server v·ªõi auto mode
      await _wsService!.sendStartListening(ListeningMode.autoStop);

      // ‚úÖ FIX: ƒê·∫£m b·∫£o recording ƒëang ch·∫°y
      if (!_audioService.isRecording) {
        _logger.i('üé§ Starting recording for listening...');
        final started = await _audioService.startRecording();
        if (!started) {
          _logger.e('‚ùå Failed to start recording');
          _updateState(BotState.error);
          _updateEmotion(BotEmotion.error);
          return;
        }
      } else {
        _logger.d('‚úÖ Recording already active');
      }

      _logger.i('‚úÖ Auto listening started');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error auto starting listening: $e');
      _updateState(BotState.error);
      _updateEmotion(BotEmotion.error);
    }
  }

  /// Auto stop listening khi h·∫øt gi·ªçng n√≥i
  Future<void> _autoStopListening() async {
    try {
      _logger.i('ü§ñ Auto stopping listening...');

      // Send stop listening to server
      await _wsService!.sendStopListening();

      // Update state to thinking
      _updateState(BotState.thinking);
      _updateEmotion(BotEmotion.thinking);

      _logger.i('‚úÖ Auto listening stopped, waiting for bot response');

      // ‚úÖ QUAN TR·ªåNG: KH√îNG t·∫Øt recording ·ªü ƒë√¢y
      // Recording s·∫Ω ti·∫øp t·ª•c ch·∫°y ƒë·ªÉ s·∫µn s√†ng cho input ti·∫øp theo
      // CH·ªà t·∫Øt khi bot b·∫Øt ƒë·∫ßu n√≥i (trong TTS playback handler)

      // Wait for response
      await Future.delayed(Duration(milliseconds: 200));

      // Flush remaining frames
      await _ttsPlayback.flushRemainingFrames();

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error auto stopping listening: $e');
    }
  }

  // ============================================================================
  // Cleanup
  // ============================================================================

  @override
  void dispose() {
    // Cancel timers
    _vadSpeechEndTimer?.cancel(); // ‚úÖ FIX 1: Cancel VAD timer
    _autoRestartTimer?.cancel();
    _autoListeningCheckTimer?.cancel();
    _speakingTimeoutTimer?.cancel(); // ‚úÖ NEW: Cancel speaking timeout

    // Cancel subscriptions
    _ttsSubscription?.cancel();
    _asrSubscription?.cancel();
    _audioDataSubscription?.cancel();
    _pcmDataSubscription?.cancel();
    _vadSubscription?.cancel();
    _autoVoiceSubscription?.cancel();
    _connectionStateSubscription?.cancel();
    _ttsPlaybackSubscription?.cancel();
    _recordingStateSubscription?.cancel(); // ‚úÖ FIX 5

    // Dispose services
    _wsService?.dispose();
    _audioService.dispose();
    _vadService.dispose();
    _ttsPlayback.dispose();

    super.dispose();
  }
}

/// Chat message model
class ChatMessage {
  final String text;
  final bool isUser;
  final DateTime timestamp;

  ChatMessage({required this.text, required this.isUser, DateTime? timestamp})
    : timestamp = timestamp ?? DateTime.now();
}
