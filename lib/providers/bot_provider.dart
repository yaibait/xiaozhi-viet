import 'dart:async';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:logger/logger.dart';
import '../models/config.dart';
import '../services/websocket_service.dart';
import '../services/activation_service.dart';
import '../services/audio_service.dart';
import '../services/vad_service.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:uuid/uuid.dart';
import 'dart:math';
import 'dart:convert';
import '../services/tts_playback_service.dart';

/// Bot states
enum BotState { idle, listening, thinking, speaking, error }

/// Bot emotions
enum BotEmotion { neutral, happy, thinking, listening, speaking, sad, error }

/// Main Bot Provider - FIXED VERSION
class BotProvider extends ChangeNotifier {
  final Logger _logger = Logger();

  // Services
  XiaozhiConfig? _config;
  XiaozhiWebSocketService? _wsService;
  ActivationService? _activationService;
  final AudioService _audioService = AudioService();
  final VadService _vadService = VadService();
  final TtsPlaybackService _ttsPlayback = TtsPlaybackService();

  // State
  BotState _state = BotState.idle;
  BotState _stateBeforeDisconnect =
      BotState.idle; // ‚úÖ FIX 4: L∆∞u state tr∆∞·ªõc disconnect
  BotEmotion _emotion = BotEmotion.neutral;
  bool _isActivated = false;
  bool _isConnected = false;
  String? _activationCode;

  // ‚úÖ FIX 1: Th√™m field ƒë·ªÉ l∆∞u listening mode
  ListeningMode _currentListeningMode = ListeningMode.autoStop;

  // ‚úÖ FIX 3: Th√™m lock ƒë·ªÉ tr√°nh race condition
  bool _isTransitioning = false;

  // ‚úÖ FIX 1: Th√™m timer cho VAD timeout
  Timer? _vadSpeechEndTimer;

  // Text
  String _currentTtsText = '';
  String _currentAsrText = '';
  final List<ChatMessage> _messages = [];
  final uuid = Uuid();

  // Subscriptions
  StreamSubscription? _ttsSubscription;
  StreamSubscription? _asrSubscription;
  StreamSubscription? _audioDataSubscription;
  StreamSubscription? _pcmDataSubscription; // For VAD
  StreamSubscription? _vadSubscription;
  StreamSubscription? _connectionStateSubscription;
  StreamSubscription? _ttsPlaybackSubscription;
  StreamSubscription? _recordingStateSubscription; // ‚úÖ FIX 5: Th√™m subscription
  // Auto voice detection mode
  bool _autoVoiceMode = false;
  bool _isMonitoringVoice = false;
  StreamSubscription? _autoVoiceSubscription;
  Timer? _autoRestartTimer;
  Timer? _autoListeningCheckTimer;
  // Getters
  BotState get state => _state;
  BotEmotion get emotion => _emotion;
  bool get isActivated => _isActivated;
  bool get isConnected => _isConnected;
  String? get activationCode => _activationCode;
  String get currentTtsText => _currentTtsText;
  String get currentAsrText => _currentAsrText;
  List<ChatMessage> get messages => List.unmodifiable(_messages);
  bool get isListening => _state == BotState.listening;
  bool get isSpeaking => _state == BotState.speaking;
  bool get autoVoiceMode => _autoVoiceMode;
  bool get isMonitoringVoice => _isMonitoringVoice;
  VadService get vadService => _vadService;
  AudioService get audioService => _audioService;
  // ============================================================================
  // Initialization
  // ============================================================================

  Future<void> initialize({String? deviceId, String? clientId}) async {
    try {
      _logger.i('ü§ñ Initializing bot...');
      final prefs = await SharedPreferences.getInstance();

      final savedDeviceId = prefs.getString('device_id');
      final savedClientId = prefs.getString('client_id');
      final serial_number = prefs.getString('serial_number');
      final hmacKey = prefs.getString('hmac_key');
      final finalDeviceId = deviceId ?? savedDeviceId ?? _generateDeviceId();
      final finalClientId = clientId ?? savedClientId ?? _generateClientId();
      final finalserialNumber =
          serial_number ?? serial_number ?? generateSerialFromUuid();
      final finalHmacKey = hmacKey ?? hmacKey ?? _generateHmacKey();

      if (savedDeviceId == null) {
        await prefs.setString('device_id', finalDeviceId);
      }
      if (savedClientId == null) {
        await prefs.setString('client_id', finalClientId);
      }

      _config = XiaozhiConfig(
        deviceId: finalDeviceId,
        clientId: finalClientId,
        serialNumber: finalserialNumber,
        hmacKey: finalHmacKey,
      );

      _activationService = ActivationService(_config!);
      _wsService = XiaozhiWebSocketService(_config!);

      _setupWebSocketCallbacks();

      _logger.i('üì° Checking activation status...');
      final response = await _activationService!.checkOtaStatus();

      if (response.needsActivation) {
        _activationCode = response.verificationCode;
        _isActivated = false;
        _updateEmotion(BotEmotion.neutral);
        _logger.i('üîë Need activation: $_activationCode');
        _startActivation();
      } else {
        _isActivated = true;
        _logger.i('‚úÖ Already activated');
        await connect();
      }

      _audioService.init();
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Initialization error: $e');
      _updateState(BotState.error);
      _updateEmotion(BotEmotion.error);
    }
  }

  String generateSerialFromUuid() {
    final u = uuid.v4().replaceAll('-', '');
    final part1 = u.substring(0, 8);
    final part2 = u.substring(20, 32);
    return 'SN-${part1}-${part2}';
  }

  String _generateHmacKey() {
    final random = Random.secure();
    final bytes = List<int>.generate(32, (_) => random.nextInt(256));
    return base64Encode(bytes);
  }

  String _generateDeviceId() {
    return randomMac();
  }

  String _toHex(int v) => v.toRadixString(16).padLeft(2, '0').toUpperCase();

  String randomMac({bool locallyAdministered = true}) {
    final rnd = Random.secure();
    final bytes = List<int>.generate(6, (_) => rnd.nextInt(256));
    int first = bytes[0];
    first = first & 0xFE;
    if (locallyAdministered) {
      first = first | 0x02;
    } else {
      first = first & 0xFD;
    }
    bytes[0] = first;
    return bytes.map(_toHex).join(':').toLowerCase();
  }

  String _generateClientId() {
    return uuid.v4().toLowerCase();
  }

  /// Setup WebSocket callbacks
  void _setupWebSocketCallbacks() {
    // TTS stream
    _ttsSubscription = _wsService!.ttsTextStream.listen((text) {
      _currentTtsText = text;
      _addMessage(ChatMessage(text: text, isUser: false));

      // ‚úÖ FIX 2: CH·ªà update state n·∫øu kh√¥ng ƒëang listening
      if (_state != BotState.listening) {
        _updateState(BotState.speaking);
        _updateEmotion(BotEmotion.speaking);
      }

      _logger.i('üîä TTS: $text');
      notifyListeners();
    });

    // ASR stream
    _asrSubscription = _wsService!.asrTextStream.listen((text) {
      _currentAsrText = text;
      _addMessage(ChatMessage(text: text, isUser: true));
      _logger.i('üé§ ASR: $text');
      notifyListeners();
    });

    // Connection state
    _connectionStateSubscription = _wsService!.connectionStateStream.listen((
      state,
    ) {
      _isConnected = state == ConnectionState.connected;
      _logger.i('üîå Connection state: $state');

      // ‚úÖ FIX 4: X·ª≠ l√Ω connection loss
      if (state == ConnectionState.disconnected && !_isConnected) {
        _handleConnectionLoss();
      }

      notifyListeners();
    });

    // Audio data stream
    _audioDataSubscription = _audioService.audioDataStream.listen((opusData) {
      // Ch·ªâ g·ª≠i audio ƒë·∫øn server khi ƒëang listening
      if (_state == BotState.listening) {
        _wsService?.sendAudio(opusData);
      }
    });

    // PCM data stream for VAD processing
    _pcmDataSubscription = _audioService.pcmDataStream.listen(
      (pcmData) {
        // Lu√¥n lu√¥n process VAD ƒë·ªÉ ph√°t hi·ªán gi·ªçng n√≥i
        _vadService.processFrame(pcmData);
      },
      onError: (error) {
        _logger.e('‚ùå PCM stream error: $error');
      },
      onDone: () {
        _logger.w('‚ö†Ô∏è PCM stream closed');
        // N·∫øu auto mode ƒëang b·∫≠t, restart recording
        if (_autoVoiceMode && _isMonitoringVoice) {
          _logger.i(
            'üîÑ PCM stream closed, restarting recording for auto mode...',
          );
          Future.delayed(Duration(milliseconds: 100), () async {
            if (_autoVoiceMode && _isMonitoringVoice) {
              await _audioService.startRecording();
            }
          });
        }
      },
    );

    // TTS Audio stream - ‚úÖ CHUNKED STREAMING VERSION
    _wsService!.onIncomingAudio((opusData) {
      _logger.d('üîä Received TTS audio: ${opusData.length} bytes');

      // ‚úÖ Add frame to streaming (s·∫Ω t·ª± ƒë·ªông t·∫°o chunk v√† play)
      _ttsPlayback.addOpusFrame(opusData);
    });

    // ‚úÖ FIX 2: TTS Playback state - v·ªõi state check v√† auto mode restart
    _ttsPlaybackSubscription = _ttsPlayback.playbackStateStream.listen((
      isPlaying,
    ) {
      if (isPlaying) {
        // CH·ªà update n·∫øu kh√¥ng ƒëang listening
        if (_state != BotState.listening) {
          _updateState(BotState.speaking);
          _updateEmotion(BotEmotion.speaking);
        }
      } else {
        // CH·ªà v·ªÅ idle n·∫øu ƒëang speaking
        if (_state == BotState.speaking) {
          _updateState(BotState.idle);
          _updateEmotion(BotEmotion.happy);

          // ‚úÖ FIX: Khi bot n√≥i xong trong auto mode, reset VAD ƒë·ªÉ s·∫µn s√†ng
          if (_autoVoiceMode && _isMonitoringVoice) {
            _logger.i(
              'üîÑ Auto mode: Bot finished speaking, ready for next input',
            );
            _vadService.reset();
          }
        }
      }
      notifyListeners();
    });

    // ‚úÖ FIX 1: VAD stream - v·ªõi mode check v√† timeout
    _vadSubscription = _vadService.vadEventStream.listen((event) {
      _logger.d(
        'üîä VAD Event: $event (state: $_state, autoMode: $_autoVoiceMode)',
      );
      // ‚úÖ CRITICAL: Skip n·∫øu auto mode ƒëang b·∫≠t (auto listener s·∫Ω x·ª≠ l√Ω)
      if (_autoVoiceMode) {
        _logger.d('‚è≠Ô∏è Auto mode active, skipping manual VAD handler');
        return;
      }
      if (event == VadEvent.speechStart) {
        _logger.d('üé§ Speech started');

        // H·ªßy timer n·∫øu ƒëang ch·ªù
        _vadSpeechEndTimer?.cancel();
        _vadSpeechEndTimer = null;

        _updateEmotion(BotEmotion.listening);
      } else if (event == VadEvent.speechEnd) {
        _logger.d('üîá Speech ended');

        // CH·ªà auto-stop n·∫øu mode l√† autoStop
        if (_state == BotState.listening &&
            _currentListeningMode == ListeningMode.autoStop) {
          // H·ªßy timer c≈© n·∫øu c√≥
          _vadSpeechEndTimer?.cancel();

          // Th√™m timeout 1.5s ƒë·ªÉ tr√°nh d·ª´ng qu√° s·ªõm
          _vadSpeechEndTimer = Timer(Duration(milliseconds: 1500), () {
            if (_state == BotState.listening) {
              _logger.i('‚è±Ô∏è VAD timeout - stopping listening');
              stopListening();
            }
          });
        }
      }
    });

    // ‚úÖ FIX 5: Recording state stream - sync v·ªõi bot state
    _recordingStateSubscription = _audioService.recordingStateStream.listen((
      isRecording,
    ) {
      if (!isRecording && _state == BotState.listening) {
        _logger.w('‚ö†Ô∏è Recording stopped unexpectedly while in listening state');
        _updateState(BotState.error);
        _updateEmotion(BotEmotion.error);
        notifyListeners();
      }
    });
  }

  /// Start activation process
  void _startActivation() async {
    try {
      _logger.i('üöÄ Starting activation...');
      final success = await _activationService!.activate();

      if (success) {
        _isActivated = true;
        _activationCode = null;
        _logger.i('‚úÖ Activation successful!');
        await connect();
      } else {
        _logger.e('‚ùå Activation failed');
        _updateState(BotState.error);
        _updateEmotion(BotEmotion.error);
      }

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Activation error: $e');
    }
  }

  // ============================================================================
  // Connection
  // ============================================================================

  /// Connect to WebSocket
  Future<void> connect() async {
    try {
      _logger.i('üîå Connecting to server...');
      final success = await _wsService!.connect();

      if (success) {
        _isConnected = true;

        // ‚úÖ FIX 4: Restore state n·∫øu ƒëang listening tr∆∞·ªõc khi m·∫•t k·∫øt n·ªëi
        if (_stateBeforeDisconnect == BotState.listening) {
          _logger.i('üîÑ Restoring listening state after reconnection');
          await startListening(mode: _currentListeningMode);
        } else {
          _updateState(BotState.idle);
          _updateEmotion(BotEmotion.happy);
        }

        _logger.i('‚úÖ Connected!');
      } else {
        _logger.e('‚ùå Connection failed');
        _updateState(BotState.error);
        _updateEmotion(BotEmotion.error);
      }

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Connection error: $e');
      _updateState(BotState.error);
      _updateEmotion(BotEmotion.error);
    }
  }

  /// ‚úÖ FIX 4: Handle connection loss
  void _handleConnectionLoss() {
    _logger.w('‚ö†Ô∏è Connection lost');
    _stateBeforeDisconnect = _state;

    // D·ª´ng recording n·∫øu ƒëang listening
    if (_state == BotState.listening) {
      _audioService.stopRecording();
    }
  }

  /// Disconnect
  Future<void> disconnect() async {
    await _wsService?.disconnect();
    _isConnected = false;
    _updateState(BotState.idle);
    notifyListeners();
  }

  // ============================================================================
  // Voice interaction
  // ============================================================================

  /// ‚úÖ FIX 1 & 3: Start listening v·ªõi lock v√† mode tracking
  Future<void> startListening({
    ListeningMode mode = ListeningMode.autoStop,
  }) async {
    // ‚úÖ FIX 3: Check lock
    if (_isTransitioning) {
      _logger.w('‚ö†Ô∏è Already transitioning state');
      return;
    }

    if (!_isConnected) {
      _logger.w('‚ö†Ô∏è Not connected');
      return;
    }

    _isTransitioning = true; // Lock

    try {
      _logger.i('üé§ Starting listening (mode: $mode)...');

      // ‚úÖ FIX AUDIO: Clear old audio buffer tr∆∞·ªõc khi start listening m·ªõi
      _ttsPlayback.startNewSession();

      // ‚úÖ FIX 1: L∆∞u listening mode
      _currentListeningMode = mode;

      // Update state
      _updateState(BotState.listening);
      _updateEmotion(BotEmotion.listening);

      // Send start listening to server
      await _wsService!.sendStartListening(mode);

      // Start audio recording
      await _audioService.startRecording();

      _logger.i('‚úÖ Listening started');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error starting listening: $e');
      _updateState(BotState.error);
    } finally {
      _isTransitioning = false; // ‚úÖ FIX 3: Unlock
    }
  }

  /// ‚úÖ STREAMING VERSION: Stop listening (ƒë∆°n gi·∫£n h∆°n nhi·ªÅu!)
  Future<void> stopListening() async {
    // ‚úÖ FIX 3: Check lock
    if (_isTransitioning) {
      _logger.w('‚ö†Ô∏è Already transitioning state');
      return;
    }

    _isTransitioning = true; // Lock

    try {
      _logger.i('üõë Stopping listening...');

      // H·ªßy VAD timer n·∫øu c√≥
      _vadSpeechEndTimer?.cancel();
      _vadSpeechEndTimer = null;

      // Stop audio recording
      await _audioService.stopRecording();

      // Send stop listening to server
      await _wsService!.sendStopListening();

      // Update state
      _updateState(BotState.thinking);
      _updateEmotion(BotEmotion.thinking);

      _logger.i('‚úÖ Listening stopped');

      // ‚úÖ STREAMING: Kh√¥ng c·∫ßn waitForAudio() n·ªØa!
      // Audio s·∫Ω t·ª± ƒë·ªông stream v√† play t·ª´ng chunk khi frames ƒë·∫øn
      // Ch·ªâ c·∫ßn ƒë·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫≠n frames ƒë·∫ßu ti√™n
      await Future.delayed(Duration(milliseconds: 200));

      // Check stream status
      final streamInfo = _ttsPlayback.getStreamInfo();
      _logger.i('üìä Stream info: $streamInfo');

      // ƒê·ª£i th√™m ƒë·ªÉ nh·∫≠n t·∫•t c·∫£ frames
      await Future.delayed(Duration(milliseconds: 500));

      // Flush remaining frames (ph·∫ßn cu·ªëi c√πng)
      await _ttsPlayback.flushRemainingFrames();

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error stopping listening: $e');
    } finally {
      _isTransitioning = false; // ‚úÖ FIX 3: Unlock
    }
  }

  /// Toggle listening
  Future<void> toggleListening() async {
    if (_state == BotState.listening) {
      await stopListening();
    } else {
      await startListening();
    }
  }

  /// Send text message
  Future<void> sendTextMessage(String text) async {
    if (!_isConnected) {
      _logger.w('‚ö†Ô∏è Not connected');
      return;
    }

    try {
      _logger.i('üì§ Sending text: $text');

      _addMessage(ChatMessage(text: text, isUser: true));
      await _wsService!.sendTextMessage(text);

      _updateState(BotState.thinking);
      _updateEmotion(BotEmotion.thinking);

      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error sending text: $e');
    }
  }

  // ============================================================================
  // State management
  // ============================================================================

  void _updateState(BotState newState) {
    if (_state != newState) {
      _state = newState;
      _logger.d('üîÑ State: $_state');
      notifyListeners();
    }
  }

  void _updateEmotion(BotEmotion newEmotion) {
    if (_emotion != newEmotion) {
      _emotion = newEmotion;
      _logger.d('üòä Emotion: $_emotion');
      notifyListeners();
    }
  }

  void _addMessage(ChatMessage message) {
    _messages.add(message);
    if (_messages.length > 100) {
      _messages.removeAt(0);
    }
  }

  /// Clear messages
  void clearMessages() {
    _messages.clear();
    notifyListeners();
  }

  // ============================================================================
  // Auto Voice Mode
  // ============================================================================

  /// Enable auto voice mode - t·ª± ƒë·ªông ph√°t hi·ªán v√† b·∫Øt ƒë·∫ßu l·∫Øng nghe
  Future<void> enableAutoVoiceMode() async {
    if (!_isConnected) {
      _logger.w('‚ö†Ô∏è Not connected - cannot enable auto voice mode');
      return;
    }

    if (_autoVoiceMode) {
      _logger.w('‚ö†Ô∏è Auto voice mode already enabled');
      return;
    }

    _logger.i('ü§ñ Enabling auto voice mode...');
    _autoVoiceMode = true;

    // B·∫Øt ƒë·∫ßu monitoring voice activity
    await _startVoiceMonitoring();

    notifyListeners();
  }

  /// Disable auto voice mode
  Future<void> disableAutoVoiceMode() async {
    if (!_autoVoiceMode) {
      _logger.w('‚ö†Ô∏è Auto voice mode already disabled');
      return;
    }

    _logger.i('üõë Disabling auto voice mode...');
    _autoVoiceMode = false;

    // D·ª´ng monitoring
    await _stopVoiceMonitoring();

    // N·∫øu ƒëang listening th√¨ stop
    if (_state == BotState.listening) {
      await stopListening();
    }

    notifyListeners();
  }

  /// Toggle auto voice mode
  Future<void> toggleAutoVoiceMode() async {
    if (_autoVoiceMode) {
      await disableAutoVoiceMode();
    } else {
      await enableAutoVoiceMode();
    }
  }

  /// B·∫Øt ƒë·∫ßu monitoring voice activity
  Future<void> _startVoiceMonitoring() async {
    if (_isMonitoringVoice) {
      _logger.w('‚ö†Ô∏è Already monitoring voice');
      return;
    }

    try {
      _logger.i('üëÇ Starting voice monitoring...');
      _isMonitoringVoice = true;

      // Reset VAD service
      _vadService.reset();

      // B·∫Øt ƒë·∫ßu recording ƒë·ªÉ monitor
      final recordingStarted = await _audioService.startRecording();
      if (!recordingStarted) {
        _logger.e('‚ùå Failed to start recording for monitoring');
        _isMonitoringVoice = false;
        return;
      }
      _logger.i('‚úÖ Recording started for monitoring');

      // Subscribe to VAD events cho auto mode
      _autoVoiceSubscription = _vadService.vadEventStream.listen(
        (event) {
          if (!_autoVoiceMode) {
            _logger.d('‚ö†Ô∏è VAD event but auto mode disabled, ignoring');
            return;
          }

          _logger.i('üîä Auto VAD Event: $event (state: $_state)');

          if (event == VadEvent.speechStart) {
            _logger.i('üé§ Auto: Speech detected - starting listening');

            // T·ª± ƒë·ªông b·∫Øt ƒë·∫ßu listening khi ph√°t hi·ªán gi·ªçng n√≥i
            if (_state == BotState.idle || _state == BotState.speaking) {
              _autoStartListening();
            } else {
              _logger.d(
                '‚ö†Ô∏è Auto: Not in idle/speaking state, current: $_state',
              );
            }
          } else if (event == VadEvent.speechEnd) {
            _logger.d('üîá Auto: Speech ended');

            // Trong auto mode, khi speech end th√¨ auto stop v√† quay v·ªÅ monitoring
            if (_state == BotState.listening) {
              _autoStopListening();
            } else {
              _logger.d('‚ö†Ô∏è Auto: Not in listening state, current: $_state');
            }
          }
        },
        onError: (error) {
          _logger.e('‚ùå Auto VAD subscription error: $error');
        },
        onDone: () {
          _logger.w('‚ö†Ô∏è Auto VAD subscription closed');
        },
      );

      _logger.i('‚úÖ Voice monitoring started');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error starting voice monitoring: $e');
      _isMonitoringVoice = false;
    }
  }

  /// D·ª´ng monitoring voice activity
  Future<void> _stopVoiceMonitoring() async {
    if (!_isMonitoringVoice) {
      return;
    }

    try {
      _logger.i('üõë Stopping voice monitoring...');

      // Cancel subscription
      _autoVoiceSubscription?.cancel();
      _autoVoiceSubscription = null;

      // Cancel timers
      _autoRestartTimer?.cancel();
      _autoRestartTimer = null;
      _autoListeningCheckTimer?.cancel();
      _autoListeningCheckTimer = null;

      // ‚úÖ FIX: LU√îN stop recording khi t·∫Øt monitoring
      await _audioService.stopRecording();

      _isMonitoringVoice = false;
      _logger.i('‚úÖ Voice monitoring stopped');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error stopping voice monitoring: $e');
    }
  }

  /// Auto start listening khi ph√°t hi·ªán gi·ªçng n√≥i
  Future<void> _autoStartListening() async {
    try {
      _logger.i('ü§ñ Auto starting listening...');

      // Clear old audio buffer
      _ttsPlayback.startNewSession();

      // Update state
      _updateState(BotState.listening);
      _updateEmotion(BotEmotion.listening);

      // Send start listening to server v·ªõi auto mode
      await _wsService!.sendStartListening(ListeningMode.autoStop);

      // ‚úÖ FIX: Recording ƒë√£ ch·∫°y r·ªìi t·ª´ monitoring, KH√îNG c·∫ßn start l·∫°i
      // Ch·ªâ c·∫ßn ƒë·∫£m b·∫£o l√† n√≥ v·∫´n ƒëang ch·∫°y
      if (!_audioService.isRecording) {
        _logger.w('‚ö†Ô∏è Recording stopped unexpectedly, restarting...');
        await _audioService.startRecording();
      }

      _logger.i('‚úÖ Auto listening started');
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error auto starting listening: $e');
    }
  }

  /// Auto stop listening khi h·∫øt gi·ªçng n√≥i
  Future<void> _autoStopListening() async {
    try {
      _logger.i('ü§ñ Auto stopping listening...');

      // Send stop listening to server
      await _wsService!.sendStopListening();

      // Update state
      _updateState(BotState.thinking);
      _updateEmotion(BotEmotion.thinking);

      _logger.i('‚úÖ Auto listening stopped');

      // Wait for response
      await Future.delayed(Duration(milliseconds: 200));

      // Flush remaining frames
      await _ttsPlayback.flushRemainingFrames();

      // ‚úÖ FIX: ƒê·ª£i bot n√≥i xong r·ªìi m·ªõi ready cho input ti·∫øp
      // Thay v√¨ d√πng timer, listen v√†o TTS playback state
      notifyListeners();
    } catch (e) {
      _logger.e('‚ùå Error auto stopping listening: $e');
    }
  }

  // ============================================================================
  // Cleanup
  // ============================================================================

  @override
  void dispose() {
    // Cancel timers
    _vadSpeechEndTimer?.cancel(); // ‚úÖ FIX 1: Cancel VAD timer
    _autoRestartTimer?.cancel();
    _autoListeningCheckTimer?.cancel();

    // Cancel subscriptions
    _ttsSubscription?.cancel();
    _asrSubscription?.cancel();
    _audioDataSubscription?.cancel();
    _pcmDataSubscription?.cancel();
    _vadSubscription?.cancel();
    _autoVoiceSubscription?.cancel();
    _connectionStateSubscription?.cancel();
    _ttsPlaybackSubscription?.cancel();
    _recordingStateSubscription?.cancel(); // ‚úÖ FIX 5

    // Dispose services
    _wsService?.dispose();
    _audioService.dispose();
    _vadService.dispose();
    _ttsPlayback.dispose();

    super.dispose();
  }
}

/// Chat message model
class ChatMessage {
  final String text;
  final bool isUser;
  final DateTime timestamp;

  ChatMessage({required this.text, required this.isUser, DateTime? timestamp})
    : timestamp = timestamp ?? DateTime.now();
}
